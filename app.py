import streamlit as st
import numpy as np
import pickle
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences

# ----------------------------------------------------------------
# LOAD SAVED MODEL AND TOKENIZER
# ----------------------------------------------------------------
# --- Load the new model and tokenizer files. This was done in the train_model.py file ---
try:
    model = load_model('emma_next_word_lstm.h5')
    with open('emma_tokenizer.pickle', 'rb') as handle:
        tokenizer = pickle.load(handle)
except Exception as e:
    st.error(f"Error loading model or tokenizer: {e}")
    st.error("Please ensure 'emma_next_word_lstm.h5' and 'emma_tokenizer.pickle' are present and generated by running train_model.py.")
    st.stop()
    
# Create a reverse mapping from index to word for faster lookups
index_to_word = {index: word for word, index in tokenizer.word_index.items()}

# ----------------------------------------------------------------
# PREDICTION FUNCTION
# ----------------------------------------------------------------
def predict_next_word(model, tokenizer, index_to_word_map, text, max_len):
    """Predicts the next word in a sequence."""
    text = text.lower()
    token_list = tokenizer.texts_to_sequences([text])[0]
    
    if not token_list:
        return "Please enter a valid sequence."

    token_list = pad_sequences([token_list], maxlen=max_len - 1, padding='pre')
    predicted_probs = model.predict(token_list, verbose=0)
    predicted_index = np.argmax(predicted_probs, axis=1)[0]
    predicted_word = index_to_word_map.get(predicted_index, "word not in vocabulary")
    
    return predicted_word

# ----------------------------------------------------------------
# STREAMLIT UI
# ----------------------------------------------------------------
st.set_page_config(page_title="Next-Word Predictor", layout="centered")
st.title("Next-Word Prediction with an LSTM Model")
# --- CHANGE: Update the descriptive text ---
st.write("This app uses a trained LSTM model to predict the next word in a sentence. The model was trained on Jane Austen's *Emma*.")
st.markdown("---")

try:
    max_sequence_len = model.input_shape[1] + 1
except Exception as e:
    st.error(f"Could not determine sequence length from the model: {e}")
    st.stop()

# --- CHANGE: Update the default input text ---
input_text = st.text_input("Enter a sequence of words:", "One half of the world cannot understand")

if st.button("Predict Next Word"):
    if input_text:
        with st.spinner("Predicting..."):
            next_word = predict_next_word(model, tokenizer, index_to_word, input_text, max_sequence_len)
            st.success(f"**Input:** `{input_text}`")
            st.success(f"**Predicted Next Word:** `{next_word}`")
    else:
        st.warning("Please enter some text.")

st.markdown("---")
st.info("To train your own model, run the `train_model.py` script.")